{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faced-insulation",
   "metadata": {},
   "source": [
    "# Machine learning does not magically create added value\n",
    "*How machine learning allows us to overcome previously imporssible challenges, but is no silver bullet*\n",
    "\n",
    "# Introduction\n",
    "- For some people, machine learning seems this magical tool: throw data at it and the algorithm will create value. \n",
    "- However, ML does not really reduce the amount of work that needs to be done, it just allows us to solve a class of problems that we could not solve before. Also note that it cannot solve all problems. It also makes some common modeling tasks obsolete, but also intoduces some new ones. \n",
    "\n",
    "# ML as a form of meta-learning: control problems and reinforcement learning\n",
    "- Simple control problem: robot should not hit the wall and get to the end. Very classical approach would be an [expert system](https://en.wikipedia.org/wiki/Expert_system):\n",
    "    - Get a bunch of experts in a room\n",
    "    - Discuss what rules the robot should follow, e.g.:\n",
    "     - Use your sensor too look ahead\n",
    "     - When an obstacle comes within range, stop\n",
    "     - Pivot around until you find a clear angle, continue driving\n",
    "    - Perform experiments and check if the robot performs well. Evaluate the rules with the expert and adapt them. \n",
    "- Reinforcement learning approach: \n",
    "    - Define what the robot knows about the world, i.e. the one distance sensor. \n",
    "    - Also define a function that defines succes for the robot, i.e. a reward function. positive if we move, negative if we hit the wall. \n",
    "    - Let the robot walk around, giving it rewards appropriate to its behavior. The RL agent will slowly learn the policy: what is a good idea in a given situation\n",
    "    - The researcher needs to tweak all the settings of the RL algorithm, e.g. learning rate, architecture of the neural network (if you use one), exploration vs exploitation setting, which reward function to use, etc.\n",
    "- Note that we switched from determine the rules ourselves to building a system that can find the rules on its own. Improving performance is not done by tweaking the rules itself, but by tweaking the learning system that then learns the rules. Effectively this is meta-learning. Meta-learning does not make our tasks easier, it does allows us to solve different problems. \n",
    "\n",
    "# Meta-learning in full effect: computer vision and CNNs\n",
    "- Elaborate more on what different classes of models we can solve by providing a nice example. \n",
    "- Write about object recognition in images using CNN. Contrast this with an expert system approach. \n",
    "\n",
    "\n",
    "# Questions:\n",
    "- Title is better, but for my taste not yet optimal. \n",
    "- Not happy with the term meta-learning. [There is a term already](https://en.wikipedia.org/wiki/Meta_learning_(computer_science)) that is not what I mean. The goal is to find something that fits with the abstraction layer idea. First we learn rules, then we learn the system that makes the rules, then we might go to AGI that learns about learning the rules. \n",
    "\n",
    "![tree](agi_to_rules.png)\n",
    "\n",
    "# Interesting angles\n",
    "\n",
    "### Increased abstraction of machine learning leads to believe in magical thinking\n",
    "- ML models become more and more abstract and hard to explain. This has a tendency to introduce an almost magical believe in what these models can do. \n",
    "- Good example is Lee Sedol, world champion Go player, that says Alpha Go is creative and plays like a human. \n",
    "\n",
    "## Classes of problems\n",
    "- Couple of features, relativly uncorrelated, not much feature engineering needed, each labeled, **functional form** reasonably well understood. \n",
    "- Very large number of features, much feature engineering needed. \n",
    "\n",
    "### Less abstract\n",
    "- Regression of milk spectra to determine fat content of milk \n",
    "- Fraud detection on 12 features\n",
    "\n",
    "### More abstract\n",
    "- Classification of photos\n",
    "- Very good chat bots\n",
    "\n",
    "## Hierarchy of models\n",
    "- low coef models: single or multiple lin regression\n",
    "- intermediate coef models: principal component regression, lasso\n",
    "- high coef models: neural networks, deep neural networks\n",
    "\n",
    "\n",
    "- Traditional models: regression, lasso, etc. Order of magnitude 1-100 coefs\n",
    "    - Feature generation and selection by the user\n",
    "    \n",
    "- Machine learning: neural nets (1000s coef) to deep neural nets (100.000s coefs - millions of coefs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
